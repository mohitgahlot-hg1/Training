{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9c03147",
   "metadata": {},
   "source": [
    "Scenario: Smart Factory Temperature Monitoring\n",
    "A factory monitors the daily average temperature (Â°C) of a critical machine.\n",
    "The goal is to predict tomorrowâ€™s temperature using the last 5 days of temperature readings in order to:\n",
    "Detect overheating trends\n",
    "Schedule preventive maintenance\n",
    "Avoid machine failure\n",
    "ðŸ”¹ Sample Dataset (Time-Series)\n",
    " \n",
    "Day\tTemperature (Â°C)\n",
    "Day 1\t68\n",
    "Day 2\t70\n",
    "Day 3\t71\n",
    "Day 4\t73\n",
    "Day 5\t74\n",
    "Day 6\t76\n",
    "Day 7\t78\n",
    "Day 8\t80\n",
    "Day 9\t82\n",
    "Day 10\t85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed38dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequencial\n",
    "from tensorflow.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2cb9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Pratik.Jadhav\\Downloads\\Training\\venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train loss (SGD): 2.220446049250313e-16\n",
      "Final val   loss (SGD): 1.1457267999649048\n",
      "Final train loss (Adam): 1.354472090042691e-14\n",
      "Final val   loss (Adam): 1.0527070760726929\n",
      "\n",
      "Last 5 days (Â°C): [76. 78. 80. 82. 85.]\n",
      "Predicted next temp (SGD) : 82.78 Â°C\n",
      "Predicted next temp (Adam): 83.19 Â°C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "temps = np.array([68, 70, 71, 73, 74, 76, 78, 80, 82, 85], dtype=np.float32)\n",
    "\n",
    "\n",
    "window_size = 5\n",
    "X_list, y_list = [], []\n",
    "for i in range(len(temps) - window_size):\n",
    "    X_list.append(temps[i:i+window_size])     # 5 consecutive days\n",
    "    y_list.append(temps[i+window_size])       # next day's temp\n",
    "\n",
    "X = np.array(X_list, dtype=np.float32)        # shape: (num_samples, 5)\n",
    "y = np.array(y_list,  dtype=np.float32)       # shape: (num_samples,)\n",
    "\n",
    "# Reshape for RNN: (batch, time_steps, features)\n",
    "X = X[..., np.newaxis]   # (num_samples, 5, 1)\n",
    "y = y[..., np.newaxis]   # (num_samples, 1)\n",
    "\n",
    "print(\"Number of samples:\", X.shape[0])  # Expect 5 samples with 10 days and window=5\n",
    "\n",
    "\n",
    "train_size = max(1, int(0.8 * len(X)))  # 4\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "\n",
    "x_mean, x_std = X_train.mean(), X_train.std() + 1e-8\n",
    "y_mean, y_std = y_train.mean(), y_train.std() + 1e-8\n",
    "\n",
    "X_train_n = (X_train - x_mean) / x_std\n",
    "X_val_n   = (X_val   - x_mean) / x_std\n",
    "y_train_n = (y_train - y_mean) / y_std\n",
    "y_val_n   = (y_val   - y_mean) / y_std\n",
    "\n",
    "\n",
    "def build_model(units=16):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units, activation='tanh', input_shape=(window_size, 1)),\n",
    "        Dense(1)  # regression output (normalized scale)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "\n",
    "sgd_opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, clipnorm=1.0)\n",
    "\n",
    "model_sgd = build_model(16)\n",
    "model_sgd.compile(optimizer=sgd_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_sgd = model_sgd.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=500,          # more epochs to compensate for tiny data\n",
    "    batch_size=2,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (SGD):\", history_sgd.history['loss'][-1])\n",
    "print(\"Final val   loss (SGD):\", history_sgd.history['val_loss'][-1])\n",
    "\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "\n",
    "model_adam = build_model(16)\n",
    "model_adam.compile(optimizer=adam_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_adam = model_adam.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=500,\n",
    "    batch_size=2,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (Adam):\", history_adam.history['loss'][-1])\n",
    "print(\"Final val   loss (Adam):\", history_adam.history['val_loss'][-1])\n",
    "\n",
    "\n",
    "last_5_days = temps[-window_size:]  # [74, 76, 78, 80, 82]\n",
    "inp = last_5_days.reshape(1, window_size, 1)\n",
    "\n",
    "\n",
    "inp_n = (inp - x_mean) / x_std\n",
    "\n",
    "pred_n_sgd  = model_sgd.predict(inp_n,  verbose=0)[0, 0]\n",
    "pred_n_adam = model_adam.predict(inp_n, verbose=0)[0, 0]\n",
    "\n",
    "\n",
    "pred_sgd  = pred_n_sgd  * y_std + y_mean\n",
    "pred_adam = pred_n_adam * y_std + y_mean\n",
    "\n",
    "print(\"\\nLast 5 days (Â°C):\", np.round(last_5_days, 2))\n",
    "print(f\"Predicted next temp (SGD) : {pred_sgd:.2f} Â°C\")\n",
    "print(f\"Predicted next temp (Adam): {pred_adam:.2f} Â°C\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a51be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 3\n",
      "Final train loss (SGD): 2.498001805406602e-16\n",
      "Final val   loss (SGD): 0.0011678278679028153\n",
      "Final train loss (Adam): 1.6709723882346594e-14\n",
      "Final val   loss (Adam): 0.09155550599098206\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000245DD0FAE60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000245DF5D0550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Last 5 days (Â°C): [32. 33. 29. 30. 32. 32. 32.]\n",
      "Predicted next temp (SGD) : 32.00 Â°C\n",
      "Predicted next temp (Adam): 32.00 Â°C\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "temps = np.array([30,31,30,32,33,29,30,32,32,32], dtype=np.float32)\n",
    "\n",
    "\n",
    "window_size = 7\n",
    "X_list, y_list = [], []\n",
    "for i in range(len(temps) - window_size):\n",
    "    X_list.append(temps[i:i+window_size])     # 5 consecutive days\n",
    "    y_list.append(temps[i+window_size])       # next day's temp\n",
    "\n",
    "X = np.array(X_list, dtype=np.float32)        # shape: (num_samples, 5)\n",
    "y = np.array(y_list,  dtype=np.float32)       # shape: (num_samples,)\n",
    "\n",
    "# Reshape for RNN: (batch, time_steps, features)\n",
    "X = X[..., np.newaxis]   # (num_samples, 5, 1)\n",
    "y = y[..., np.newaxis]   # (num_samples, 1)\n",
    "\n",
    "print(\"Number of samples:\", X.shape[0])  # Expect 5 samples with 10 days and window=5\n",
    "\n",
    "\n",
    "train_size = max(1, int(0.8 * len(X)))  # 4\n",
    "X_train, X_val = X[:train_size], X[train_size:]\n",
    "y_train, y_val = y[:train_size], y[train_size:]\n",
    "\n",
    "x_mean, x_std = X_train.mean(), X_train.std() + 1e-8\n",
    "y_mean, y_std = y_train.mean(), y_train.std() + 1e-8\n",
    "\n",
    "X_train_n = (X_train - x_mean) / x_std\n",
    "X_val_n   = (X_val   - x_mean) / x_std\n",
    "y_train_n = (y_train - y_mean) / y_std\n",
    "y_val_n   = (y_val   - y_mean) / y_std\n",
    "\n",
    "def build_model(units=16):\n",
    "    model = Sequential([\n",
    "        SimpleRNN(units, activation='tanh', input_shape=(window_size, 1)),\n",
    "        Dense(1)  # regression output (normalized scale)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "sgd_opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9, clipnorm=1.0)\n",
    "\n",
    "model_sgd = build_model(16)\n",
    "model_sgd.compile(optimizer=sgd_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_sgd = model_sgd.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=500,          # more epochs to compensate for tiny data\n",
    "    batch_size=2,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (SGD):\", history_sgd.history['loss'][-1])\n",
    "print(\"Final val   loss (SGD):\", history_sgd.history['val_loss'][-1])\n",
    "\n",
    "adam_opt = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
    "\n",
    "model_adam = build_model(16)\n",
    "model_adam.compile(optimizer=adam_opt, loss='mse', metrics=['mae'])\n",
    "\n",
    "history_adam = model_adam.fit(\n",
    "    X_train_n, y_train_n,\n",
    "    epochs=500,\n",
    "    batch_size=2,\n",
    "    validation_data=(X_val_n, y_val_n),\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Final train loss (Adam):\", history_adam.history['loss'][-1])\n",
    "print(\"Final val   loss (Adam):\", history_adam.history['val_loss'][-1])\n",
    "\n",
    "\n",
    "last_5_days = temps[-window_size:]  # [74, 76, 78, 80, 82]\n",
    "inp = last_5_days.reshape(1, window_size, 1)\n",
    "\n",
    "\n",
    "inp_n = (inp - x_mean) / x_std\n",
    "\n",
    "pred_n_sgd  = model_sgd.predict(inp_n,  verbose=0)[0, 0]\n",
    "pred_n_adam = model_adam.predict(inp_n, verbose=0)[0, 0]\n",
    "\n",
    "\n",
    "pred_sgd  = pred_n_sgd  * y_std + y_mean\n",
    "pred_adam = pred_n_adam * y_std + y_mean\n",
    "\n",
    "print(\"\\nLast 5 days (Â°C):\", np.round(last_5_days, 2))\n",
    "print(f\"Predicted next temp (SGD) : {pred_sgd:.2f} Â°C\")\n",
    "print(f\"Predicted next temp (Adam): {pred_adam:.2f} Â°C\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee22b5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
