{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3768e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os, random\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "SEED = 42\n",
    "DATA_ROOT = \"data\"\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 0          # safest in Colab (no dataloader worker issues)\n",
    "EPOCHS_HEAD = 2\n",
    "EPOCHS_FT = 5\n",
    "LR_HEAD = 1e-3\n",
    "LR_FT_BACKBONE = 1e-5\n",
    "LR_FT_HEAD = 5e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "BEST_WEIGHTS_PATH = \"best_resnet50_eurosat_3cls.pt\"\n",
    "BEST_CKPT_PATH    = \"best_resnet50_eurosat_3cls.pth\"  # includes metadata\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0d9b8e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m\n\u001b[0;32m     13\u001b[0m val_tfms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     14\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((IMG_SIZE, IMG_SIZE)),\n\u001b[0;32m     15\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     16\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(IMAGENET_MEAN, IMAGENET_STD),\n\u001b[0;32m     17\u001b[0m ])\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Load EuroSAT base dataset (PIL images)\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m base_ds \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEuroSAT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_ROOT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m class_names \u001b[38;5;241m=\u001b[39m base_ds\u001b[38;5;241m.\u001b[39mclasses\n\u001b[0;32m     22\u001b[0m name_by_idx \u001b[38;5;241m=\u001b[39m {i: n \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(class_names)}\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\eurosat.py:42\u001b[0m, in \u001b[0;36mEuroSAT.__init__\u001b[1;34m(self, root, transform, target_transform, download, loader)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2750\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\eurosat.py:67\u001b[0m, in \u001b[0;36mEuroSAT.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     66\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 67\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://huggingface.co/datasets/torchgeo/eurosat/resolve/c877bcd43f099cd0196738f714544e355477f3fd/EuroSAT.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mc8fa014336c82ac7804f0398fcb19387\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\utils.py:388\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    386\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 388\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    390\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    391\u001b[0m extract_archive(archive, extract_root, remove_finished)\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\utils.py:118\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    115\u001b[0m     _download_file_from_remote_location(fpath, url)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# expand redirect chain if needed\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43m_get_redirect_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_hops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_redirect_hops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# check if file is located on Google Drive\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     file_id \u001b[38;5;241m=\u001b[39m _get_google_drive_file_id(url)\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\utils.py:63\u001b[0m, in \u001b[0;36m_get_redirect_url\u001b[1;34m(url, max_hops)\u001b[0m\n\u001b[0;32m     60\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT}\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_hops \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;241m==\u001b[39m url \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39murl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m url\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:557\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    555\u001b[0m     http_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    556\u001b[0m args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, proto, meth_name) \u001b[38;5;241m+\u001b[39m args\n\u001b[1;32m--> 557\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:749\u001b[0m, in \u001b[0;36mHTTPRedirectHandler.http_error_302\u001b[1;34m(self, req, fp, code, msg, headers)\u001b[0m\n\u001b[0;32m    746\u001b[0m fp\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m    747\u001b[0m fp\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m--> 749\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Mohit.gahlot\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "])\n",
    "\n",
    "# Load EuroSAT base dataset (PIL images)\n",
    "base_ds = torchvision.datasets.EuroSAT(root=DATA_ROOT, download=True, transform=None)\n",
    "class_names = base_ds.classes\n",
    "name_by_idx = {i: n for i, n in enumerate(class_names)}\n",
    "print(\"EuroSAT classes:\", class_names)\n",
    "\n",
    "# Map EuroSAT -> 3 classes\n",
    "# Urban = Residential + Industrial + Highway\n",
    "# Forest = Forest\n",
    "# Water = River + SeaLake\n",
    "EUROSAT_TO_3 = {\n",
    "    \"Residential\": 0,\n",
    "    \"Industrial\": 0,\n",
    "    \"Highway\": 0,\n",
    "    \"Forest\": 1,\n",
    "    \"River\": 2,\n",
    "    \"SeaLake\": 2,\n",
    "}\n",
    "THREE_CLASS_NAMES = [\"Urban\", \"Forest\", \"Water\"]\n",
    "\n",
    "# Filter usable indices\n",
    "kept_indices = []\n",
    "kept_targets = []\n",
    "for i in range(len(base_ds)):\n",
    "    _, y = base_ds[i]\n",
    "    cname = name_by_idx[y]\n",
    "    if cname in EUROSAT_TO_3:\n",
    "        kept_indices.append(i)\n",
    "        kept_targets.append(EUROSAT_TO_3[cname])\n",
    "\n",
    "print(f\"Keeping {len(kept_indices)} images for 3-class task.\")\n",
    "\n",
    "# Stratified split into train/val/test\n",
    "def stratified_split_3way(indices, labels, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    random.seed(seed)\n",
    "    by_class = defaultdict(list)\n",
    "    for idx, lab in zip(indices, labels):\n",
    "        by_class[lab].append(idx)\n",
    "\n",
    "    train_idx, val_idx, test_idx = [], [], []\n",
    "    for lab, idxs in by_class.items():\n",
    "        random.shuffle(idxs)\n",
    "        n = len(idxs)\n",
    "        n_val = int(n * val_ratio)\n",
    "        n_test = int(n * test_ratio)\n",
    "        val_idx.extend(idxs[:n_val])\n",
    "        test_idx.extend(idxs[n_val:n_val+n_test])\n",
    "        train_idx.extend(idxs[n_val+n_test:])\n",
    "\n",
    "    random.shuffle(train_idx); random.shuffle(val_idx); random.shuffle(test_idx)\n",
    "    return train_idx, val_idx, test_idx\n",
    "\n",
    "train_indices, val_indices, test_indices = stratified_split_3way(\n",
    "    kept_indices, kept_targets, val_ratio=0.15, test_ratio=0.15, seed=SEED\n",
    ")\n",
    "\n",
    "print(\"Train:\", len(train_indices), \"Val:\", len(val_indices), \"Test:\", len(test_indices))\n",
    "\n",
    "# Dataset wrapper (apply tfms + remap labels)\n",
    "class EuroSAT3Class(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, indices, tfms):\n",
    "        self.base = base_dataset\n",
    "        self.indices = indices\n",
    "        self.tfms = tfms\n",
    "        self.name_by_idx = {i: n for i, n in enumerate(self.base.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        real_idx = self.indices[i]\n",
    "        img, y = self.base[real_idx]\n",
    "        cname = self.name_by_idx[y]\n",
    "        y3 = EUROSAT_TO_3[cname]\n",
    "        if self.tfms is not None:\n",
    "            img = self.tfms(img)\n",
    "        return img, y3\n",
    "\n",
    "train_ds = EuroSAT3Class(base_ds, train_indices, train_tfms)\n",
    "val_ds   = EuroSAT3Class(base_ds, val_indices, val_tfms)\n",
    "test_ds  = EuroSAT3Class(base_ds, test_indices, val_tfms)  # test uses val transforms\n",
    "\n",
    "pin = True if device == \"cuda\" else False\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=pin)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aff6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torchvision.models.ResNet50_Weights.DEFAULT\n",
    "model = torchvision.models.resnet50(weights=weights)\n",
    "model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def accuracy_from_logits(logits, targets):\n",
    "    preds = logits.argmax(dim=1)\n",
    "    return (preds == targets).float().mean().item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc  += accuracy_from_logits(out, y) * bs\n",
    "        n += bs\n",
    "    return total_loss / n, total_acc / n\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    total_loss, total_acc, n = 0.0, 0.0, 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        bs = x.size(0)\n",
    "        total_loss += loss.item() * bs\n",
    "        total_acc  += accuracy_from_logits(out, y) * bs\n",
    "        n += bs\n",
    "\n",
    "    return total_loss / n, total_acc / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758eb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = 0.0\n",
    "scaler = torch.cuda.amp.GradScaler() if device == \"cuda\" else None\n",
    "\n",
    "# ---------- Stage 1: train head only ----------\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.fc.parameters(), lr=LR_HEAD, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "print(\"\\n=== Stage 1: Training classifier head ===\")\n",
    "for epoch in range(1, EPOCHS_HEAD + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    va_loss, va_acc = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"[Head] Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f}\")\n",
    "\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        torch.save(model.state_dict(), BEST_WEIGHTS_PATH)\n",
    "\n",
    "# ---------- Stage 2: fine-tune layer4 + head ----------\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.layer4.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "params = [\n",
    "    {\"params\": model.layer4.parameters(), \"lr\": LR_FT_BACKBONE},\n",
    "    {\"params\": model.fc.parameters(),     \"lr\": LR_FT_HEAD},\n",
    "]\n",
    "optimizer = torch.optim.AdamW(params, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_FT)\n",
    "\n",
    "print(\"\\n=== Stage 2: Fine-tuning layer4 + head ===\")\n",
    "for epoch in range(1, EPOCHS_FT + 1):\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scaler)\n",
    "    va_loss, va_acc = evaluate(model, val_loader)\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"[FT]   Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.4f} | val loss {va_loss:.4f} acc {va_acc:.4f} | best {best_val_acc:.4f}\")\n",
    "\n",
    "    if va_acc > best_val_acc:\n",
    "        best_val_acc = va_acc\n",
    "        torch.save(model.state_dict(), BEST_WEIGHTS_PATH)\n",
    "\n",
    "print(f\"\\n‚úÖ Training done. Best Val Acc: {best_val_acc:.4f}\")\n",
    "print(f\"‚úÖ Best weights saved to: {BEST_WEIGHTS_PATH}\")\n",
    "\n",
    "# Save a full checkpoint with metadata (recommended)\n",
    "ckpt = {\n",
    "    \"model_state\": torch.load(BEST_WEIGHTS_PATH, map_location=\"cpu\"),\n",
    "    \"class_names\": THREE_CLASS_NAMES,\n",
    "    \"img_size\": IMG_SIZE,\n",
    "    \"mean\": IMAGENET_MEAN,\n",
    "    \"std\": IMAGENET_STD,\n",
    "    \"eurosat_to_3\": EUROSAT_TO_3,\n",
    "}\n",
    "torch.save(ckpt, BEST_CKPT_PATH)\n",
    "print(f\"‚úÖ Full checkpoint saved to: {BEST_CKPT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c576749c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_pil(pil_img):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ])\n",
    "    x = tfm(pil_img.convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "    logits = model(x)\n",
    "    probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    pred = int(np.argmax(probs))\n",
    "    conf = float(probs[pred])\n",
    "    return pred, conf, probs\n",
    "\n",
    "# pick 20 random test indices\n",
    "sample = random.sample(test_indices, 20)\n",
    "\n",
    "plt.figure(figsize=(16, 14))\n",
    "for i, idx in enumerate(sample, start=1):\n",
    "    img, y_orig = base_ds[idx]              # PIL image + original EuroSAT label\n",
    "    cname = name_by_idx[y_orig]\n",
    "    true = EUROSAT_TO_3[cname]              # true mapped label\n",
    "\n",
    "    pred, conf, probs = predict_pil(img)\n",
    "\n",
    "    ax = plt.subplot(5, 4, i)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    title = f\"P:{THREE_CLASS_NAMES[pred]} ({conf*100:.1f}%)\\nT:{THREE_CLASS_NAMES[true]}\"\n",
    "    ax.set_title(title, color=(\"green\" if pred == true else \"red\"), fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5195bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, shutil\n",
    "\n",
    "os.makedirs(\"sample_test_images\", exist_ok=True)\n",
    "\n",
    "for i, idx in enumerate(sample):\n",
    "    img, y_orig = base_ds[idx]\n",
    "    cname = name_by_idx[y_orig]\n",
    "    true = EUROSAT_TO_3[cname]\n",
    "    img.save(f\"sample_test_images/{i+1:02d}_TRUE_{THREE_CLASS_NAMES[true]}.png\")\n",
    "\n",
    "zip_path = \"sample_test_images.zip\"\n",
    "with zipfile.ZipFile(zip_path, \"w\") as z:\n",
    "    for f in os.listdir(\"sample_test_images\"):\n",
    "        z.write(os.path.join(\"sample_test_images\", f), arcname=f)\n",
    "\n",
    "print(\"‚úÖ Created:\", zip_path)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52530d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import files\n",
    "from IPython.display import clear_output, display\n",
    "from PIL import Image\n",
    "\n",
    "# Directory to store temporary uploaded images\n",
    "UPLOAD_DIR = \"/content/upload_temp\"\n",
    "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "\n",
    "def remove_uploaded():\n",
    "    \"\"\"Delete uploaded images + clear output.\"\"\"\n",
    "    for f in os.listdir(UPLOAD_DIR):\n",
    "        os.remove(os.path.join(UPLOAD_DIR, f))\n",
    "    clear_output()\n",
    "    print(\"üóëÔ∏è All uploaded images removed. You can upload new ones now.\")\n",
    "\n",
    "while True:\n",
    "    print(\"üìå Options:\")\n",
    "    print(\"1Ô∏è‚É£  Upload Image\")\n",
    "    print(\"2Ô∏è‚É£  Remove Uploaded Images\")\n",
    "    print(\"3Ô∏è‚É£  Exit\")\n",
    "    choice = input(\"Enter choice (1/2/3): \")\n",
    "\n",
    "    # ============================\n",
    "    # OPTION 1 ‚Äî UPLOAD IMAGE\n",
    "    # ============================\n",
    "    if choice == \"1\":\n",
    "        clear_output()\n",
    "        uploaded = files.upload()  # upload any image\n",
    "\n",
    "        for fn in uploaded.keys():\n",
    "            path = os.path.join(UPLOAD_DIR, fn)\n",
    "            with open(path, 'wb') as f:\n",
    "                f.write(uploaded[fn])\n",
    "\n",
    "            img = Image.open(path).convert(\"RGB\")\n",
    "            display(img)\n",
    "\n",
    "            pred, conf, probs = predict_pil(img)\n",
    "\n",
    "            print(\"\\n==========================\")\n",
    "            print(\"üõ∞Ô∏è  PREDICTION RESULT\")\n",
    "            print(\"==========================\")\n",
    "            print(f\"Predicted Class: {THREE_CLASS_NAMES[pred]}\")\n",
    "            print(f\"Confidence: {conf*100:.2f}%\")\n",
    "\n",
    "            print(\"\\nüìä Class Probabilities:\")\n",
    "            for i, c in enumerate(THREE_CLASS_NAMES):\n",
    "                print(f\"  {c:>6}: {probs[i]*100:.2f}%\")\n",
    "\n",
    "        print(\"\\nüëâ You can choose again (upload / remove / exit).\")\n",
    "\n",
    "    # ============================\n",
    "    # OPTION 2 ‚Äî REMOVE / RESET\n",
    "    # ============================\n",
    "    elif choice == \"2\":\n",
    "        remove_uploaded()\n",
    "\n",
    "    # ============================\n",
    "    # OPTION 3 ‚Äî EXIT LOOP\n",
    "    # ============================\n",
    "    elif choice == \"3\":\n",
    "        print(\"üëã Exiting. You can run this cell again anytime.\")\n",
    "        break\n",
    "\n",
    "    else:\n",
    "        clear_output()\n",
    "        print(\"‚ö†Ô∏è Invalid choice! Please enter 1, 2, or 3.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
